import spacy
from textblob import TextBlob
import pandas as pd

try:
    nlp = spacy.load("en_core_web_sm")  # V√©rifie si le mod√®le est install√©
except OSError:
    print("Le mod√®le en_core_web_sm n'est pas install√©. Installation en cours...")
    import subprocess
    subprocess.run(["python", "-m", "spacy", "download", "en_core_web_sm"], check=True)
    # Charger le mod√®le spaCy pour identifier les entit√©s nomm√©es (villes, pays, monuments...)
    # Extraction d'entit√©s nomm√©es NER (Named Entity Recognition) lieux, personnes organisation, date etc...
    nlp = spacy.load("en_core_web_sm")  # Charger apr√®s installation


def top_10_poi(dataframe):
    #creation d'une liste vide pour stocker les POI
    Liste_Poi_Sentiment = []
    #normalement, je n'ai pas lire le csv, c'est df_destination qui est en param√®tre
    for index, row in dataframe.iterrows():
        #on r√©cup√®re le transcript
        text = str(row.get("Transcript", "")).strip()
        if not text:
            continue
        # on extrait les lieux du transcript par vid√©o
        doc = nlp(text)
        # Extraire les entit√©s d'int√©r√™t (lieux, monuments, infrastructures)
        # GPE c'est les lieux = ville, pays, r√©gion, 
        # LOC c'est les monuments = mus√©e, ch√¢teau, √©glise, etc...,
        # FAC c'est les infrastructures = a√©roport, gare, etc...
        # on cr√©e une liste de comprehension pour r√©cup√©rer les lieux
        pois = [ent.text for ent in doc.ents if ent.label_ in ["GPE", "LOC", "FAC"]]
        # si une liste pois ne contient aucun Poi, on met None
        if not pois:
            pois = ["Aucun POI d√©tect√©"]
        
        #on r√©cup√®re les sentiments et la note pour chaque POI
        #on utilise textblob pour analyser le sentiment
        #pouquoi textblob ? car il est plus simple et plus rapide que spacy
        blob = TextBlob(text)
        # il permet la d√©coupe de texte en phrases via sentences
        # pour chaque phrase, on r√©cup√®re le sentiment
        for sentence in blob.sentences:
            #pour chaque phrase, on regarde si le POI est pr√©sent
            for poi in pois:  
                #si le POI est pr√©sent dans la phrase alosr on r√©cup√®re le sentiment
                if poi in sentence:
                    sentiment_score = sentence.sentiment.polarity  
                    # Ajouter POI et sentiment √† la liste
                    Liste_Poi_Sentiment.append({"POI": poi, "Sentiment": sentiment_score})
    
    #je cr√©e un dataframe avec les POI et le sentiment
    poi_destination = pd.DataFrame(Liste_Poi_Sentiment)
    
    #on groupe par POI  
    poi_destination = poi_destination.groupby("POI").agg(
    #on fait la somme de chaque POI
    Frequency=("POI", "count"),
    #on fait la moyenne des sentiments par POI
    AvgSentiment=("Sentiment", "mean")
    ).reset_index()
    
    # Classement final
    #Prendre la valeur absolue du sentiment pour √©viter les biais
    poi_destination["Score"] = poi_destination["Frequency"] * poi_destination["AvgSentiment"]**2
    poi_destination = poi_destination.sort_values(by="Score", ascending=False).head(10)
    
    return poi_destination
    
    
    
        
    









# Ce bloc de code permet d'√©viter que le script soit ex√©cut√© automatiquement lorsqu'il est 
# import√© dans un autre fichier.
# Il ne s'ex√©cute que si ce fichier est ex√©cut√© directement via `python recup_url_yt.py`.
if __name__ == "__main__":
    print("üîπ Test en mode standalone : ce script est ex√©cut√© directement.")